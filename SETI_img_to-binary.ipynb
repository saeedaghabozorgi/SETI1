{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.cognitiveclass.ai\"><img src = \"https://cognitiveclass.ai/wp-content/themes/bdu3.0/static/images/cc-logo.png\" align = left></a>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "--------------------\n",
    "# Signal to Binary Files (Train&Test) \n",
    "\n",
    "In this notebook we read the Basic 4 dataset and convert signals into a binary file. The format of output binary file is same as MNIST."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!sudo pip install ibmseti"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import ibmseti\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import os\n",
    "from PIL import Image\n",
    "from matplotlib import cm\n",
    "from array import array"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets first create a working folder, and set parameters:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "ds_zip_file = 'SETI_ds_64x128.tar.gz'\n",
    "ds_directory = 'tmp/SETI1_data/SETI_ds_64x128/'  # The dataset directory to write the binary files\n",
    "if not os.path.exists(ds_directory):\n",
    "    os.makedirs(ds_directory)\n",
    "#remove its content\n",
    "os.system('rm '+ds_directory+'*')\n",
    "print os.popen(\"ls -lrt \"+ ds_directory).read()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "h and w are the hight and width of the images, and lengthRatio is the length of signal in ratio."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "h = 64 # The hight of output image (bins)\n",
    "w = 128 # The witdh of output image\n",
    "lengthRatio = 1.0  # the length-ration of signal to be read. The higher reatio, the better resolution. E.g. 0.5 means half of time sereis."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Get the file list\n",
    "\n",
    "I have a list of simulated files stored in an OpenStack Object Storage container that is world-readable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Images\n",
    "base_url = 'https://62a44.https.cdn.softlayer.net/seti'\n",
    "container = 'Basic4'\n",
    "# list of images\n",
    "r = requests.get('{}/{}/{}'.format(base_url, container, 'index.csv'))\n",
    "filelist_txt = r.text"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Lets create a generator to read the file:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def filetext_gen(filelist_txt):\n",
    "    results = filelist_txt.splitlines()[1:]\n",
    "    for result in results:\n",
    "        yield result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "This file has 4 classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "dictClass = dict({u'narrowband': 2, u'narrowbanddrd': 1, u'noise': 3, u'squiggle': 0})\n",
    "dictClass"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Train/Test\n",
    "    \n",
    "We split our data into train and test set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "#At first, use just 20 percent and 10 percent. This will be useful \n",
    "#as you prototype. Then you can come back here and increase these\n",
    "#percentages as needed.\n",
    "\n",
    "training_percentage = 0.80\n",
    "test_percentage = 0.20\n",
    "\n",
    "assert training_percentage + test_percentage <= 1.0\n",
    "\n",
    "uuids_classes_as_list = map(lambda row:row, filetext_gen(filelist_txt))\n",
    "print \"found {} files\".format(len(uuids_classes_as_list))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "lets group files by classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "uuids_group_by_class={}\n",
    "for item in filetext_gen(filelist_txt): \n",
    "    uuid, sigclass =  item.split(',')\n",
    "    uuids_group_by_class.setdefault(sigclass, []).append(item)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "Now, split file list into test and train based on classes:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "training_set_group_by_class = {}\n",
    "test_set_group_by_class = {}\n",
    "for k, v in uuids_group_by_class.iteritems():\n",
    "    \n",
    "    total = len(v)\n",
    "    training_size = int(total * training_percentage)\n",
    "    test_size = int(total * test_percentage)\n",
    "    \n",
    "    training_set = v[:training_size]\n",
    "    test_set = v[-1*test_size:]\n",
    "    \n",
    "    training_set_group_by_class[k] = training_set\n",
    "    test_set_group_by_class[k] = test_set\n",
    "    \n",
    "    print '{}: training set size: {}'.format(k, len(training_set))\n",
    "    print '{}: test set size: {}'.format(k, len(test_set))\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "all_training_set = []\n",
    "for k, v, in training_set_group_by_class.iteritems():\n",
    "    print k\n",
    "    for item in v:\n",
    "        all_training_set.append(item)\n",
    "print 'number of files in the training set:' , len(all_training_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "all_test_set = []\n",
    "for k, v, in test_set_group_by_class.iteritems():\n",
    "    print k\n",
    "    for item in v:\n",
    "        all_test_set.append(item)\n",
    "print 'number of files in the test set:' ,  len(all_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "###  Send request to fetch data, and convert signals to spectogram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def get_spectrogram(fname,h,w,lengthRatio=1.0):\n",
    "    \n",
    "    r = requests.get('{}/{}/{}'.format(base_url, container, fname), timeout=4.0)\n",
    "    if r.status_code != 200:\n",
    "        print 'Failed retrieving {}'.format(fname)\n",
    "        print r\n",
    "        return None\n",
    "    else:\n",
    "        aca = ibmseti.compamp.SimCompamp(r.content)\n",
    "        com_data = aca.complex_data()\n",
    "        ratio = int(np.sqrt(len(com_data) *lengthRatio / (h*w)))\n",
    "        if ratio == 0: \n",
    "            raise ValueError, \"The selected lenght of signal is less than (Height x Width), select bigger ratio\"\n",
    "        elif ratio == 1:\n",
    "            sig_data = com_data[:h*w].reshape(h,w)\n",
    "            spec = np.abs( np.fft.fftshift( np.fft.fft(sig_data), 1) )**2\n",
    "            spec = np.log(spec)\n",
    "            spec = spec/np.max(spec) # Convert to float (0-1)\n",
    "            image = Image.fromarray(cm.jet(spec, bytes=True)) #convert to RGB\n",
    "        elif ratio > 1: # resize using IPL image\n",
    "            sig_data = com_data[:h*ratio*w*ratio].reshape(h*ratio,w*ratio)\n",
    "            spec = np.abs( np.fft.fftshift( np.fft.fft(sig_data), 1) )**2\n",
    "            spec = np.log(spec) # Convert to float (0-255)\n",
    "            spec = spec/np.max(spec) # Convert to float (0-1)\n",
    "            image = Image.fromarray(cm.jet(spec, bytes=True)) #convert to RGB  \n",
    "            image = image.resize((int(w), int(h)), Image.ANTIALIAS)\n",
    "\n",
    "        \n",
    "        return image\n",
    "#test\n",
    "\n",
    "img_spec = get_spectrogram('b1cc342f-eae4-442b-91de-10c9a444072e.dat',h,w, 1.0)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.imshow(img_spec)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Grayscale image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "img = img_spec.convert(\"L\")\n",
    "imgarr = np.array(img, dtype=np.uint8) \n",
    "im = Image.fromarray(np.uint8(imgarr))\n",
    "im\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "imgarr.flatten()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Write image content into a Binary file\n",
    "This binary file is same as famouse __mnist__ dataset format to be read by different image processing algorithms, learning techniques and pattern recognition methods. \n",
    "\n",
    "There are 4 files:  \n",
    "\n",
    "- train-images-idx3-ubyte: training set images \n",
    "- train-labels-idx1-ubyte: training set labels \n",
    "- test-images-idx3-ubyte:  test set images \n",
    "- test-labels-idx1-ubyte:  test set labels\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Header generator"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Notice:\n",
    "\n",
    "- Header of Label file is 8 Bytes\n",
    "- Each number (int-8bit), is one Byte in array(B)\n",
    "- For header, the first 4 bytes is 2049 \n",
    "- the second 4 bytes is the number of files\n",
    "- for example, the header for 10 file is [0, 0, 8, 1, 0, 0, 0, 10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def label_generator(ds_directory, name, data_set):\n",
    "    counter = 0\n",
    "    data_label = array('B')\n",
    "    n = len(data_set)\n",
    "\n",
    "    # number of files in HEX\n",
    "    hexval = \"{0:#0{1}x}\".format(n,6)  # the result is '0x000a'\n",
    "\n",
    "    # header for label array\n",
    "    #data_label.extend(lblData)\n",
    "    lb_header = array('B')\n",
    "    # in the next 3 lines we create 10 bytes header\n",
    "    lb_header.extend([0,0,8,1,0,0])  # -> \"{0:#0{1}x}\".format(2049,6) = '0x0801'\n",
    "    lb_header.append(int('0x'+hexval[2:][:2],16)) # it adds 2 bytes '0x00'\n",
    "    lb_header.append(int('0x'+hexval[2:][2:],16)) # it adds 2 bytes '0x0a'\n",
    "    print lb_header\n",
    "    with open(ds_directory + name+'-labels-idx1-ubyte','wb+') as f:\n",
    "        f.write(lb_header)\n",
    "        for item in data_set: \n",
    "            uuid, sigclass =  item.split(',')\n",
    "            # print uuid,sigclass\n",
    "            f.write(np.uint8(dictClass[sigclass]))\n",
    "            counter += 1\n",
    "#             if counter > n:\n",
    "#                 break\n",
    "        print 'The number of labels written in the binary file', counter\n",
    "            \n",
    "    os.system('gzip '+ ds_directory + name +'-labels-idx1-ubyte ')\n",
    "    print ('done!')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "label_generator(ds_directory, 'train', all_training_set)\n",
    "label_generator(ds_directory, 'test', all_test_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Image generator"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def image_generator(ds_directory, name, data_set):\n",
    "    print 'writing to:',  ds_directory , name\n",
    "    counter = 0\n",
    "\n",
    "    data_image = array('B')\n",
    "\n",
    "    n = len(data_set)\n",
    "\n",
    "    # number of files in HEX\n",
    "    hexval = \"{0:#0{1}x}\".format(n,6) \n",
    "\n",
    "    img_header = array('B')\n",
    "    img_header.extend([0,0,8,1,0,0])\n",
    "    img_header.append(int('0x'+hexval[2:][:2],16))\n",
    "    img_header.append(int('0x'+hexval[2:][2:],16))\n",
    "    if max([w,h]) <= 255:\n",
    "        img_header.extend([0,0,0,h,0,0,0,w])\n",
    "    else:\n",
    "        hex_h = \"{0:#0{1}x}\".format(h,6)\n",
    "        img_header.extend([0,0])\n",
    "        img_header.append(int('0x'+hex_h[2:][:2],16))\n",
    "        img_header.append(int('0x'+hex_h[2:][2:],16))\n",
    "        hex_w = \"{0:#0{1}x}\".format(w,6)\n",
    "        img_header.extend([0,0])\n",
    "        img_header.append(int('0x'+hex_w[2:][:2],16))\n",
    "        img_header.append(int('0x'+hex_w[2:][2:],16))\n",
    "        #raise ValueError('Image exceeds maximum size: 256x256 pixels');\n",
    "    img_header[3] = 3 # Changing MSB for image data (0x00000803)\n",
    "    #print img_header\n",
    "\n",
    "\n",
    "    with open(ds_directory+name+'-images-idx3-ubyte','wb+') as f:\n",
    "        f.write(img_header)\n",
    "        for item in data_set: \n",
    "            uuid, sigclass =  item.split(',')\n",
    "            file_name = uuid +'.dat'\n",
    "            #print file_name, sigclass\n",
    "            img_spec = get_spectrogram(file_name, h, w, lengthRatio)\n",
    "            # convert to grayscale: int(0-255)\n",
    "            gimg = img_spec.convert(\"L\")\n",
    "            imgarr = np.array(gimg, dtype=np.uint8) #convert to array\n",
    "            flat_array = imgarr.flatten()\n",
    "            f.write((flat_array))\n",
    "            counter += 1\n",
    "            if counter%100 == 0:\n",
    "                print('Processed files: '+str(counter))\n",
    "#             if counter > n:\n",
    "#                 break\n",
    "        print 'The number of images written in the binary file', counter\n",
    "    print 'Compressing .. '\n",
    "    os.system('gzip '+ ds_directory + name +'-images-idx3-ubyte '+ name +'-images-idx3-ubyte.gz')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "'problematic files, to be filtered'\n",
    "'1c396696-baac-418b-9c14-bd798172ac61.dat'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "image_generator(ds_directory, 'train', all_training_set)\n",
    "image_generator(ds_directory, 'test', all_test_set)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print os.popen(\"ls -lrt \"+ ds_directory).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Compress everything"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "os.system('tar -cvzf '+ ds_zip_file +' -C '+ ds_directory +' .')\n",
    "os.system('mv '+ ds_zip_file +' '+ \"/\".join(ds_directory.split('/')[0:-2]))\n",
    "#tar -cvzf SETI_ds_64x128.tar.gz -C  tmp1/SETI_ds_64x128/ ."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Verify the binary files\n",
    "Lets read the binary file and plot an image"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print os.popen(\"ls -lrt \"+ ds_directory).read()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Header read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "def _read32(bytestream): # this function reads 4 Bytes (32 bit)\n",
    "  dt = np.dtype(np.uint32).newbyteorder('>')\n",
    "  return np.frombuffer(bytestream.read(4), dtype=dt)[0] # it reads 4 bytes, and convert it into intiger\n",
    "\n",
    "with open(ds_directory+'train-labels-idx1-ubyte.gz', 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f ) as bytestream:\n",
    "     print  _read32(bytestream)\n",
    "     num_items = _read32(bytestream)\n",
    "     print num_items\n",
    "     buf = bytestream.read(num_items)\n",
    "     labels = np.frombuffer(buf, dtype=np.uint8)\n",
    "     print labels"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "# Image read"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import gzip\n",
    "def _read32(bytestream):\n",
    "  dt = np.dtype(np.uint32).newbyteorder('>')\n",
    "  return np.frombuffer(bytestream.read(4), dtype=dt)[0]\n",
    "\n",
    "with open(ds_directory+'train-images-idx3-ubyte.gz', 'rb') as f:\n",
    "    with gzip.GzipFile(fileobj=f ) as bytestream:\n",
    "        magic = _read32(bytestream)\n",
    "        if magic != 2051:\n",
    "            raise ValueError('Invalid magic number %d in MNIST image file: %s' %(magic, f.name))\n",
    "        num_images = _read32(bytestream)\n",
    "        rows = _read32(bytestream)\n",
    "        cols = _read32(bytestream)\n",
    "        buf = bytestream.read(rows * cols * num_images)\n",
    "        print(magic,num_images,rows,cols,)\n",
    "        \n",
    "        data = np.frombuffer(buf, dtype=np.uint8)\n",
    "        data = data.reshape(num_images, rows, cols, 1)\n",
    "# magic, num, rows, cols = struct.unpack(\">IIII\", bytestream.read(16))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import random\n",
    "for i in range(5):\n",
    "    num = random.randint(1,num_images)\n",
    "    #print num\n",
    "    gray_y = data[num].reshape(h,w)\n",
    "    img = Image.fromarray(np.float32(gray_y))\n",
    "    #print (img.mode)\n",
    "    fig, ax = plt.subplots(figsize=(10, 5))\n",
    "    ax.imshow(img)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "gray_y"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Verify the binary files by reader class\n",
    "__SETI.py__ is a helper class, identical to mnist dataset reader, to easily read dataset, one-hot coding, and read images as batch."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "!wget -q --output-document SETI.zip  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\n",
    "!unzip -o SETI.zip\n",
    "import SETI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "SETIds = SETI.read_data_sets(ds_directory, one_hot=True, validation_size=0)\n",
    "SETIds.train.num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "gray_y = SETIds.train.images[0].reshape(h,w)\n",
    "img = Image.fromarray(gray_y*255)\n",
    "fig, ax = plt.subplots(figsize=(10, 5))\n",
    "ax.imshow(img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?\n",
    "\n",
    "[Deep Learning with TensorFlow](http://cocl.us/SETI-NIMBIX-ML0102EN) is a free course in __cognitiveclass.ia__ where you can learn TensorFlow and Deep Learning togetherwe.\n",
    "\n",
    "Also, running deep learning programs usually needs a high performance platform. PowerAI speeds up deep learning and AI. Built on IBM's Power Systems, PowerAI is a scalable software platform that accelerates deep learning and AI with blazing performance for individual users or enterprises. The PowerAI platform supports popular machine learning libraries and dependencies including Tensorflow, Caffe, Torch, and Theano. You can download a [free version of PowerAI](http://cocl.us/SETI-NIMBIX-PowerAI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Authors\n",
    "\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "#### Saeed Aghabozorgi\n",
    "\n",
    "[Saeed Aghabozorgi](https://ca.linkedin.com/in/saeedaghabozorgi), PhD is Sr. Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clients’ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  },
  "widgets": {
   "state": {},
   "version": "1.1.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
