{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.cognitiveclass.ai\"><img src = \"https://cognitiveclass.ai/wp-content/themes/bdu3.0/static/images/cc-logo.png\" align = left></a>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "--------------------\n",
    "# Search for Extra Terrestrial Intelligence (SETI)\n",
    "###  SETI Signal Classification on PowerAI with Multi GPU\n",
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Introduction\n",
    "In this Notebook, we will use the famous [SETI Dataset](https://github.com/setiQuest/ML4SETI/) to build a Convolutional Neural Networks capable to perform signals classification. CNN will say, with some associated error, what type of signal is the presented input. In this notebook, you will use IBM PowerAI with multiple GPU to train the model.\n",
    "\n",
    "### Project overview:\n",
    "Each night, using the Allen Telescope Array (ATA) in northern California, the SETI Institute scans the sky at various radio frequencies, observing star systems with known exoplanets, searching for faint but persistent signals. The current signal detection system is programmed to search only for particular kinds of signals: narrow-band carrier waves. However, the detection system sometimes triggers on signals that are not narrow-band signals  (with unknown efficiency) and are also not explicitly-known radio frequency interference (RFI). There seems to be various categories of these kinds of events that have been observed in the past.\n",
    "\n",
    "Our goal is to classify these accurately in real-time. This may allow the signal detection system to make better observational decisions, increase the efficiency of the nightly scans, and allow for explicit detection of these other signal types.\n",
    "\n",
    "For more information refer to [SETI hackathon page](https://github.com/setiQuest/ML4SETI/).\n",
    "\n",
    "\n",
    "Framing the radio signal data into spectrogram (a 2D visual representation), we can convert the problem into something akin to an image classification problem. CNN, will be run on the images which are the result of converting the signals to spectrogram.\n",
    "\n",
    "### Training on Multi-GPU:\n",
    "Today, many systems contains multiple GPUs for high performance computation. We can leverage this environments to run the training operation concurrently across multiple cards. One sample of these kind of environments is [IBM PowerAI](http://cocl.us/SETI-NIMBIX-PowerAI). In this notebook, we show you how to design and run your model on multiple GPUs.\n",
    "\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/usr/lib/python2.7/dist-packages/matplotlib/font_manager.py:273: UserWarning: Matplotlib is building the font cache using fc-list. This may take a moment.\n",
      "  warnings.warn('Matplotlib is building the font cache using fc-list. This may take a moment.')\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[33mThe directory '/home/nimbix/.cache/pip/http' or its parent directory is not owned by the current user and the cache has been disabled. Please check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "\u001b[33mThe directory '/home/nimbix/.cache/pip' or its parent directory is not owned by the current user and caching wheels has been disabled. check the permissions and owner of that directory. If executing pip with sudo, you may want sudo's -H flag.\u001b[0m\n",
      "Collecting sklearn\n",
      "  Downloading sklearn-0.0.tar.gz\n",
      "Requirement already satisfied: scikit-learn in /usr/lib/python2.7/dist-packages (from sklearn)\n",
      "Installing collected packages: sklearn\n",
      "  Running setup.py install for sklearn ... \u001b[?25ldone\n",
      "\u001b[?25hSuccessfully installed sklearn-0.0\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "#import ibmseti\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time\n",
    "!sudo pip install sklearn\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from six.moves import urllib\n",
    "import sys\n",
    "import tarfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set the destination folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/SETI1_data\n",
      "/tmp/SETI1_train\n"
     ]
    }
   ],
   "source": [
    "### SET YOUR WORKING SPACE HERE! Use this folder to save intermediate results.\n",
    "mydatafolder = \"/tmp/SETI1_data\"\n",
    "if os.path.exists(mydatafolder) is False:\n",
    "    os.makedirs(mydatafolder)\n",
    "print mydatafolder\n",
    "\n",
    "train_dir = '/tmp/SETI1_train'\n",
    "if os.path.exists(train_dir) is False:\n",
    "    os.makedirs(train_dir)\n",
    "print train_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Import dataset reader\n",
    "The signals for this notebook, have been converted to spectogram images, and stored as 4 files.\n",
    "The following cell will load a python code that help us to decode the binary file, and read the SETI dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  SETI.zip\n",
      "  inflating: SETI.py                 \n",
      "  inflating: __MACOSX/._SETI.py      \n"
     ]
    }
   ],
   "source": [
    "!wget -q --output-document  SETI.zip  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\n",
    "!unzip -o SETI.zip\n",
    "import SETI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Download data\n",
    "The dataset exist and shared on IBM box. Running the following cell, you can download the dataset and extract it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      ">> Downloading qz33lcio9ip2j8qi2atxqs62gn3bnu2s.gz 100.0%()\n",
      "('Successfully downloaded', 'qz33lcio9ip2j8qi2atxqs62gn3bnu2s.gz', 2432541, 'bytes.')\n"
     ]
    }
   ],
   "source": [
    "def maybe_download_and_extract():\n",
    "    data_dir = \"/tmp/SETI1_data\"\n",
    "    DATA_URL =  'https://ibm.box.com/shared/static/qz33lcio9ip2j8qi2atxqs62gn3bnu2s.gz'\n",
    "    dest_directory = data_dir\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "        sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    extracted_dir_path = os.path.join(dest_directory, 'SETI_ds_64x128')\n",
    "    if not os.path.exists(extracted_dir_path):\n",
    "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Load data SETI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/test-images-idx3-ubyte.gz\n",
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/test-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(694, 8192)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_directory = mydatafolder + '/SETI_ds_64x128/'\n",
    "dataset = SETI.read_data_sets(ds_directory, one_hot=True, validation_size=0)\n",
    "dataset.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Understanding the imported data\n",
    "\n",
    "The imported data can be divided as follow:\n",
    "\n",
    "- Training (dataset.train) >>  Use the given dataset with inputs and related outputs for training of NN. In our case, if you give an image that you know that represents a \"class1\", this set will tell the neural network that we expect a \"class1\" as the output.  \n",
    "        - 694 signals (images)\n",
    "        - dataset.train.images for inputs\n",
    "        - dataset.train.labels for outputs\n",
    "  \n",
    "  \n",
    "- Test (mnist.test) >> the model does not have access to this informations prior to the test phase. It is used to evaluate the performance and accuracy of the model against \"real life situations\". No further optimization beyond this point.  \n",
    "        - 10,000 data points\n",
    "        - dataset.test.images for inputs\n",
    "        - dataset.test.labels for outputs\n",
    "        \n",
    "        \n",
    "#### Labels\n",
    "- Each image (spectrum of signal) in the dataset has been labeled from 1 to 4, representing:\n",
    "    - squiggle\n",
    "    - narrowband\n",
    "    - noise\n",
    "    - narrowbanddrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Network Parameters\n",
    "\n",
    "We place the parameters on CPU.   \n",
    "__Notice:__ This code is not optimal for single-GPU training due to the cost of copying parameters between CPU and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "decay_rate=0.96  #decay every 1000 steps with a base of 0.96:\n",
    "decay_steps=1000\n",
    "learning_rate = 0.005\n",
    "training_epochs = 300\n",
    "batch_size = 50\n",
    "display_step = 100\n",
    "MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "use_fp16 = False\n",
    "\n",
    "#check point directory\n",
    "chk_directory = train_dir +'/save/'\n",
    "checkpoint_path = chk_directory + 'model.ckpt'\n",
    "\n",
    "\n",
    "NUM_CLASSES = 4 # number of possible classifications for the problem\n",
    "dropout = 0.50 # Dropout, probability to keep units\n",
    "\n",
    "height = 64 # height of the image in pixels \n",
    "width = 128 # width of the image in pixels \n",
    "n_input = width * height # number of pixels in one image \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### How to use multi GPU for training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "PowerAI supports multi-GPU calculation.  Given multiple GPU cards, we run the SETI model on each GPU as following:\n",
    "\n",
    "    1. Store all model parameters on the CPU.\n",
    "    2. Put a copy of the SETI model on each GPU.\n",
    "    3. Divide up a large batch of data across the GPUs, and feed each model replica with a unique batch of data.\n",
    "    4. Compute the inference on each GPU\n",
    "    5. Calculate the gradients on each GPU\n",
    "    6. Wait until all GPUs finish processing of their batches\n",
    "    7. Update model parameters synchronously on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Variable definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We define all variables using __tf.get_variable()__ in order to place the variables on CPU to be shares across multiple GPU for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    with tf.device('/cpu:0'):\n",
    "        dtype = tf.float16 if use_fp16 else tf.float32\n",
    "        var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "    dtype = tf.float16 if use_fp16 else tf.float32\n",
    "    var = _variable_on_cpu(name, shape,tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n",
    "    if wd is not None:\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Inference\n",
    "\n",
    "This function builds the graph as far as required for running the network forward to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images):\n",
    "\n",
    "    # conv1\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights', shape=[5, 5, 1, 32], stddev=0.1,  wd=0.0)\n",
    "        conv = tf.nn.conv2d(images, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [32], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "    # pool1\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool1')\n",
    "    # norm1\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "\n",
    "    # conv2\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights', shape=[5, 5, 32, 64],  stddev=0.1,  wd=0.0)\n",
    "        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "    # norm2\n",
    "    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,  name='norm2')\n",
    "    # pool2\n",
    "    pool2 = tf.nn.max_pool(norm2, ksize=[1, 2, 2, 1], strides=[1, 4, 4, 1], padding='SAME', name='pool2')\n",
    "    \n",
    "    \n",
    "    # local3\n",
    "    with tf.variable_scope('local3') as scope:\n",
    "        # Move everything into depth so we can perform a single matrix multiply.\n",
    "        reshape = tf.reshape(pool2, [batch_size, -1])\n",
    "        dim = reshape.get_shape()[1].value\n",
    "        weights = _variable_with_weight_decay('weights', shape=[dim, 1024], stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [1024], tf.constant_initializer(0.1))\n",
    "        local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "\n",
    "    # local4\n",
    "    with tf.variable_scope('local4') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', shape=[1024, 256],  stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [256], tf.constant_initializer(0.1))\n",
    "        local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "        #_activation_summary(local4)\n",
    "\n",
    "    # linear layer(WX + b),\n",
    "    # We don't apply softmax here because\n",
    "    # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits\n",
    "    # and performs the softmax internally for efficiency.\n",
    "    with tf.variable_scope('softmax_linear') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', [256, NUM_CLASSES],  stddev=1/256.0, wd=0.0)\n",
    "        biases = _variable_on_cpu('biases', [NUM_CLASSES], tf.constant_initializer(0.0))\n",
    "        softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "    #_activation_summary(softmax_linear)\n",
    "\n",
    "    return softmax_linear"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Loss function\n",
    "loss function, adds the ops required to generate loss, to the inference graph. It calculates the average cross entropy loss across the batch.  \n",
    "\n",
    "The total loss in calc_loss is defined as the cross entropy loss plus all of the weight decay terms (L2 loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(logits, labels):\n",
    "    \"\"\"Add L2Loss to all the trainable variables.\"\"\"\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "    tf.add_to_collection('losses', cross_entropy_mean)\n",
    "    return tf.add_n(tf.get_collection('losses'), name='total_loss')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we want to run the CNN on multiple GPUs, we construct our model in a multi-tower fashion where each tower is assigned to a different GPU. The following function calculate the loss value for each tower."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the total loss on a single tower running the SETI model.\n",
    "def tower_loss(scope, images, labels):\n",
    "    # Build inference Graph.\n",
    "    logits = inference(images)\n",
    "    _=calc_loss(logits, labels)\n",
    "\n",
    "    # Assemble all of the losses for the current tower only.\n",
    "    # 'losses' is the key for collection\n",
    "    # scope is for e.g. 'tower_0'\n",
    "    losses = tf.get_collection('losses', scope)\n",
    "\n",
    "    # Calculate the total loss for the current tower.\n",
    "    total_loss = tf.add_n(losses, name='total_loss')\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradients\n",
    "  \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "\n",
    "  Note that this function provides a synchronization point across all towers.\n",
    "\n",
    "  Args:\n",
    "    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n",
    "      is over individual gradients. The inner list is over the gradient\n",
    "      calculation for each tower.\n",
    "  Returns:\n",
    "     List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "     across all towers.\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "    # Note that each grad_and_vars looks like the following:\n",
    "    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(axis=0, values=grads)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a variable to track the global step.\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "# create learning_decay\n",
    "# Decay the learning rate exponentially based on the number of steps.\n",
    "lr = tf.train.exponential_decay( learning_rate,\n",
    "                                 global_step,\n",
    "                                 decay_steps,\n",
    "                                 decay_rate, staircase=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Use the optimizer to apply the gradients that minimize the loss\n",
    "# (and also increment the global step counter) as a single training step.\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "\n",
    "# Calculate the gradients for the batch of data on this SETI tower.\n",
    "#grads = opt.compute_gradients(loss)\n",
    "\n",
    "#train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "#train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get images and labels for SETI.\n",
    "x_batch, y_batch = dataset.train.next_batch(batch_size,shuffle=True)\n",
    "x_image = tf.reshape(x_batch, [-1,height,width,1]) \n",
    "labels = tf.reshape(y_batch,[-1,NUM_CLASSES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     with tf.name_scope(\"test12\"):\n",
    "#         logit1 = inference(x_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Calculate the gradients for each model tower.\n",
    "tower_grads = []\n",
    "with tf.variable_scope(tf.get_variable_scope()):\n",
    "    for i in xrange(4):\n",
    "        with tf.device('/gpu:%d' % i):\n",
    "            with tf.name_scope('%s_%d' % ('tower_', i)) as scope:\n",
    "                # read one batch for the GPU\n",
    "                x_batch, y_batch = dataset.train.next_batch(batch_size,shuffle=True)\n",
    "                image_batch = tf.reshape(x_batch, [-1,height,width,1]) \n",
    "                #label_batch = tf.reshape(y_batch,[-1,NUM_CLASSES])\n",
    "                # Calculate the loss for one tower of the SETI model. This function\n",
    "                # constructs the entire SETI model but shares the variables across\n",
    "                # all towers.\n",
    "                loss = tower_loss(scope, image_batch, y_batch)\n",
    "                # Reuse variables for the next tower.\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "                grads = optimizer.compute_gradients(loss)\n",
    "                tower_grads.append(grads)\n",
    "# on CPU                \n",
    "grads = average_gradients(tower_grads)\n",
    "# Apply the gradients to adjust the shared variables.\n",
    "apply_gradient_op = optimizer.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "# Track the moving averages of all trainable variables.\n",
    "variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "# Group all updates to into a single train op.\n",
    "# we call train_op in learning process\n",
    "# tf.group Creates an op that groups multiple operations.\n",
    "# When this op finishes, all ops in input have finished. This op has no output.\n",
    "train_op = tf.group(apply_gradient_op, variables_averages_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def evaluate():\n",
    "    X_test = dataset.test.images\n",
    "    image_test = tf.reshape(X_test, [-1,height,width,1]) \n",
    "    y_test = dataset.test.labels\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    with tf.name_scope('xx') as scope:\n",
    "        logits_test = inference(image_test)\n",
    "        # Calculate predictions.\n",
    "    top_k_op = tf.nn.in_top_k(logits_test, y_test, 1)\n",
    "    return top_k_op\n",
    "with tf.name_scope(\"t\"):\n",
    "    evaluate()\n",
    "    \n",
    "correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Create checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "directory = os.path.dirname(chk_directory)\n",
    "try:\n",
    "    os.stat(directory)\n",
    "    ckpt = tf.train.get_checkpoint_state(chk_directory)\n",
    "    print ckpt\n",
    "except:\n",
    "    os.mkdir(directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "loss_values = []\n",
    "\n",
    "X_test = dataset.test.images\n",
    "y_test = dataset.test.labels\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "# load previously trained model if appilcable\n",
    "ckpt = tf.train.get_checkpoint_state(chk_directory)\n",
    "if ckpt:\n",
    "    print \"loading model: \",ckpt.model_checkpoint_path\n",
    "    #saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "694"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step = 0\n",
    "num_examples = dataset.train.num_examples\n",
    "num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 , g_step: 0013 , E_time= 16.99464 , lr= 0.005000000 , cost= 22.792268753\n",
      "Epoch: 0011 , g_step: 0143 , E_time= 0.46558 , lr= 0.005000000 , cost= 22.620203018\n",
      "Epoch: 0021 , g_step: 0273 , E_time= 0.45872 , lr= 0.005000000 , cost= 22.238647461\n",
      "Epoch: 0031 , g_step: 0403 , E_time= 0.45459 , lr= 0.005000000 , cost= 22.043088913\n",
      "Epoch: 0041 , g_step: 0533 , E_time= 0.45677 , lr= 0.005000000 , cost= 21.919942856\n",
      "Epoch: 0051 , g_step: 0663 , E_time= 0.46048 , lr= 0.005000000 , cost= 21.805158615\n",
      "Epoch: 0061 , g_step: 0793 , E_time= 0.46224 , lr= 0.005000000 , cost= 21.692844391\n",
      "Epoch: 0071 , g_step: 0923 , E_time= 0.46246 , lr= 0.005000000 , cost= 21.581773758\n",
      "Epoch: 0081 , g_step: 1053 , E_time= 0.47043 , lr= 0.004800000 , cost= 21.473638535\n",
      "Epoch: 0091 , g_step: 1183 , E_time= 0.45431 , lr= 0.004800000 , cost= 21.368890762\n",
      "Epoch: 0101 , g_step: 1313 , E_time= 0.44924 , lr= 0.004800000 , cost= 21.265052795\n",
      "Epoch: 0111 , g_step: 1443 , E_time= 0.46565 , lr= 0.004800000 , cost= 21.162006378\n",
      "Epoch: 0121 , g_step: 1573 , E_time= 0.45941 , lr= 0.004800000 , cost= 21.059457779\n",
      "Epoch: 0131 , g_step: 1703 , E_time= 0.45270 , lr= 0.004800000 , cost= 20.957786560\n",
      "Epoch: 0141 , g_step: 1833 , E_time= 0.45480 , lr= 0.004800000 , cost= 20.856973648\n",
      "Epoch: 0151 , g_step: 1963 , E_time= 0.45679 , lr= 0.004800000 , cost= 20.756546021\n",
      "Epoch: 0161 , g_step: 2093 , E_time= 0.46386 , lr= 0.004608000 , cost= 20.659742355\n",
      "Epoch: 0171 , g_step: 2223 , E_time= 0.46147 , lr= 0.004608000 , cost= 20.564506531\n",
      "Epoch: 0181 , g_step: 2353 , E_time= 0.45680 , lr= 0.004608000 , cost= 20.469820023\n",
      "Epoch: 0191 , g_step: 2483 , E_time= 0.46240 , lr= 0.004608000 , cost= 20.375905991\n",
      "Epoch: 0201 , g_step: 2613 , E_time= 0.46405 , lr= 0.004608000 , cost= 20.282316208\n",
      "Epoch: 0211 , g_step: 2743 , E_time= 0.45300 , lr= 0.004608000 , cost= 20.189268112\n",
      "Epoch: 0221 , g_step: 2873 , E_time= 0.46008 , lr= 0.004608000 , cost= 20.096641541\n",
      "Epoch: 0231 , g_step: 3003 , E_time= 0.45055 , lr= 0.004423679 , cost= 20.004549026\n",
      "Epoch: 0241 , g_step: 3133 , E_time= 0.45838 , lr= 0.004423679 , cost= 19.916568756\n",
      "Epoch: 0251 , g_step: 3263 , E_time= 0.46205 , lr= 0.004423679 , cost= 19.829015732\n",
      "Epoch: 0261 , g_step: 3393 , E_time= 0.46568 , lr= 0.004423679 , cost= 19.741882324\n",
      "Epoch: 0271 , g_step: 3523 , E_time= 0.46490 , lr= 0.004423679 , cost= 19.654802322\n",
      "Epoch: 0281 , g_step: 3653 , E_time= 0.46157 , lr= 0.004423679 , cost= 19.568641663\n",
      "Epoch: 0291 , g_step: 3783 , E_time= 0.45941 , lr= 0.004423679 , cost= 19.482599258\n",
      "('Wall Time:', '154.1', 'sec')\n",
      "Optimization Finished!\n",
      "model saved to /tmp/SETI1_train/save/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/SETI1_train/save/model.ckpt-3600'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training cycle\n",
    "t_start = time.time()\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0.\n",
    "    #dataset.shuffle_data()\n",
    "    total_batch = int(num_examples / batch_size)\n",
    "\n",
    "    # Loop over all batches in one epoch\n",
    "    start = time.time()\n",
    "    for step in range(total_batch):\n",
    "        _, loss_value = sess.run([train_op, loss])\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "    end = time.time()    \n",
    "    # Display model every 1 epochs\n",
    "    if epoch >= 0 and epoch % 10 == 0:\n",
    "        plr = sess.run(lr)\n",
    "        g_step = sess.run(global_step)\n",
    "        loss_values.append(loss_value)\n",
    "        print \"Epoch:\", '%04d' % (epoch+1) , \", g_step:\", '%04d' % (g_step) , \", E_time=\" , \"{:.5f}\".format(end - start) , \", lr=\", \"{:.9f}\".format(plr), \", cost=\", \"{:.9f}\".format(loss_value)\n",
    "t_end = time.time()\n",
    "print(\"Wall Time:\",\"{:.1f}\".format(t_end - t_start), \"sec\")\n",
    "print(\"Optimization Finished!\")\n",
    "print (\"model saved to {}\".format(checkpoint_path))\n",
    "saver.save(sess, checkpoint_path, global_step = (epoch+1)*step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX0AAAEACAYAAABfxaZOAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\n/B/Ujh0MjsKRAAAAAUlEQVSLUlInQAAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x14005d66a6d0>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([np.mean(loss_values[i:i+5]) for i in range(len(loss_values))])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Want to learn more?\n",
    "\n",
    "Running deep learning programs usually needs a high performance platform. PowerAI speeds up deep learning and AI. Built on IBM's Power Systems, PowerAI is a scalable software platform that accelerates deep learning and AI with blazing performance for individual users or enterprises. The PowerAI platform supports popular machine learning libraries and dependencies including Tensorflow, Caffe, Torch, and Theano. You can download a [free version of PowerAI](http://cocl.us/SETI-NIMBIX-PowerAI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Authors\n",
    "\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "#### Saeed Aghabozorgi\n",
    "\n",
    "[Saeed Aghabozorgi](https://ca.linkedin.com/in/saeedaghabozorgi), PhD is Sr. Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clientsâ€™ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
