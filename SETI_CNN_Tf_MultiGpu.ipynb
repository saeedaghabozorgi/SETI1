{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.cognitiveclass.ai\"><img src = \"https://cognitiveclass.ai/wp-content/themes/bdu3.0/static/images/cc-logo.png\" align = left></a>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "--------------------\n",
    "# SETI CNN using TF and Binary DS"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Requirement already satisfied: sklearn in /usr/local/lib/python2.7/dist-packages\r\n",
      "Requirement already satisfied: scikit-learn in /usr/local/lib/python2.7/dist-packages (from sklearn)\r\n"
     ]
    }
   ],
   "source": [
    "import requests\n",
    "import json\n",
    "#import ibmseti\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time\n",
    "!sudo pip install sklearn\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from six.moves import urllib\n",
    "import sys\n",
    "import tarfile\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Set your team folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/tmp/SETI1_data\n",
      "/tmp/SETI1_train\n"
     ]
    }
   ],
   "source": [
    "### SET YOUR TEAM NAME HERE! Use this folder to save intermediate results\n",
    "mydatafolder = \"/tmp/SETI1_data\"\n",
    "if os.path.exists(mydatafolder) is False:\n",
    "    os.makedirs(mydatafolder)\n",
    "print mydatafolder\n",
    "\n",
    "train_dir = '/tmp/SETI1_train'\n",
    "if os.path.exists(train_dir) is False:\n",
    "    os.makedirs(train_dir)\n",
    "print train_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Import dataset reader\n",
    "The following cell will load a python code to read the SETI dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  SETI.zip\r\n",
      "  inflating: SETI.py                 \r\n",
      "  inflating: __MACOSX/._SETI.py      \r\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/root/anaconda2/lib/python2.7/site-packages/numpy/core/machar.py:127: RuntimeWarning: overflow encountered in add\n",
      "  a = a + a\n",
      "/root/anaconda2/lib/python2.7/site-packages/numpy/core/machar.py:129: RuntimeWarning: invalid value encountered in subtract\n",
      "  temp1 = temp - a\n",
      "/root/anaconda2/lib/python2.7/site-packages/numpy/core/machar.py:138: RuntimeWarning: invalid value encountered in subtract\n",
      "  itemp = int_conv(temp-a)\n",
      "/root/anaconda2/lib/python2.7/site-packages/numpy/core/machar.py:162: RuntimeWarning: overflow encountered in add\n",
      "  a = a + a\n",
      "/root/anaconda2/lib/python2.7/site-packages/numpy/core/machar.py:164: RuntimeWarning: invalid value encountered in subtract\n",
      "  temp1 = temp - a\n",
      "/root/anaconda2/lib/python2.7/site-packages/numpy/core/machar.py:171: RuntimeWarning: invalid value encountered in subtract\n",
      "  if any(temp-a != zero):\n"
     ]
    }
   ],
   "source": [
    "!wget -q --output-document  SETI.zip  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\n",
    "!unzip -o SETI.zip\n",
    "import SETI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Download data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "()\n",
      "('Successfully downloaded', 'qz33lcio9ip2j8qi2atxqs62gn3bnu2s.gz', 2432541, 'bytes.')\n"
     ]
    }
   ],
   "source": [
    "def maybe_download_and_extract():\n",
    "    data_dir = \"/tmp/SETI1_data\"\n",
    "    DATA_URL =  'https://ibm.box.com/shared/static/qz33lcio9ip2j8qi2atxqs62gn3bnu2s.gz'\n",
    "    dest_directory = data_dir\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "        sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "    print()\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    extracted_dir_path = os.path.join(dest_directory, 'SETI_ds_64x128')\n",
    "    if not os.path.exists(extracted_dir_path):\n",
    "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Load data SETI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/train-images-idx3-ubyte.gz\n",
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/train-labels-idx1-ubyte.gz\n",
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/test-images-idx3-ubyte.gz\n",
      "Extracting /tmp/SETI1_data/SETI_ds_64x128/test-labels-idx1-ubyte.gz\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(694, 8192)"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_directory = mydatafolder + '/SETI_ds_64x128/'\n",
    "dataset = SETI.read_data_sets(ds_directory, one_hot=True, validation_size=0)\n",
    "dataset.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Network Parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "decay_rate=0.96  #decay every 1000 steps with a base of 0.96:\n",
    "decay_steps=1000\n",
    "learning_rate = 0.005\n",
    "training_epochs = 300\n",
    "batch_size = 50\n",
    "display_step = 100\n",
    "MOVING_AVERAGE_DECAY = 0.9999     # The decay to use for the moving average.\n",
    "use_fp16 = False\n",
    "\n",
    "#check point directory\n",
    "chk_directory = train_dir+'/save/'\n",
    "checkpoint_path = chk_directory + 'model.ckpt'\n",
    "\n",
    "\n",
    "NUM_CLASSES = 4 # number of possible classifications for the problem\n",
    "dropout = 0.50 # Dropout, probability to keep units\n",
    "\n",
    "height = 64 # height of the image in pixels \n",
    "width = 128 # width of the image in pixels \n",
    "n_input = width * height # number of pixels in one image \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Inputs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "    #wd: add L2Loss weight decay multiplied by this float. If None, weight decay is not added for this Variable.\n",
    "    dtype = tf.float16 if use_fp16 else tf.float32\n",
    "    var = _variable_on_cpu(name, shape,tf.truncated_normal_initializer(stddev=stddev, dtype=dtype))\n",
    "    if wd is not None:\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    with tf.device('/cpu:0'):\n",
    "        dtype = tf.float16 if use_fp16 else tf.float32\n",
    "        var = tf.get_variable(name, shape, initializer=initializer, dtype=dtype)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def inference(images):\n",
    "    # We instantiate all variables using tf.get_variable() instead of\n",
    "    # tf.Variable() in order to share variables across multiple GPU training runs.\n",
    "    # If we only ran this model on a single GPU, we could simplify this function\n",
    "    # by replacing all instances of tf.get_variable() with tf.Variable().\n",
    "    #\n",
    "    # conv1\n",
    "    with tf.variable_scope('conv1') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights', shape=[5, 5, 1, 32], stddev=0.1,  wd=0.0)\n",
    "        conv = tf.nn.conv2d(images, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [32], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        #_activation_summary(conv1)\n",
    "\n",
    "    # pool1\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool1')\n",
    "    # norm1\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "\n",
    "    # conv2\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights', shape=[5, 5, 32, 64],  stddev=0.1,  wd=0.0)\n",
    "        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "        #_activation_summary(conv2)\n",
    "\n",
    "    # norm2\n",
    "    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,  name='norm2')\n",
    "    # pool2\n",
    "    pool2 = tf.nn.max_pool(norm2, ksize=[1, 2, 2, 1], strides=[1, 4, 4, 1], padding='SAME', name='pool2')\n",
    "    \n",
    "    \n",
    "    # local3\n",
    "    with tf.variable_scope('local3') as scope:\n",
    "        # Move everything into depth so we can perform a single matrix multiply.\n",
    "        reshape = tf.reshape(pool2, [batch_size, -1])\n",
    "        dim = reshape.get_shape()[1].value\n",
    "        weights = _variable_with_weight_decay('weights', shape=[dim, 1024], stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [1024], tf.constant_initializer(0.1))\n",
    "        local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "        #_activation_summary(local3)\n",
    "\n",
    "    # local4\n",
    "    with tf.variable_scope('local4') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', shape=[1024, 256],  stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [256], tf.constant_initializer(0.1))\n",
    "        local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "        #_activation_summary(local4)\n",
    "\n",
    "    # linear layer(WX + b),\n",
    "    # We don't apply softmax here because\n",
    "    # tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits\n",
    "    # and performs the softmax internally for efficiency.\n",
    "    with tf.variable_scope('softmax_linear') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', [256, NUM_CLASSES],  stddev=1/256.0, wd=0.0)\n",
    "        biases = _variable_on_cpu('biases', [NUM_CLASSES], tf.constant_initializer(0.0))\n",
    "        softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "    #_activation_summary(softmax_linear)\n",
    "\n",
    "    return softmax_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Loss function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def calc_loss(logits, labels):\n",
    "    \"\"\"Add L2Loss to all the trainable variables.\"\"\"\n",
    "    # Calculate the average cross entropy loss across the batch.\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "    tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "    # The total loss is defined as the cross entropy loss plus all of the weight decay terms (L2 loss).\n",
    "    return tf.add_n(tf.get_collection('losses'), name='total_loss')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the total loss on a single tower running the SETI model.\n",
    "def tower_loss(scope, images, labels):\n",
    "    # Build inference Graph.\n",
    "    logits = inference(images)\n",
    "    _=calc_loss(logits, labels)\n",
    "\n",
    "    # Assemble all of the losses for the current tower only.\n",
    "    # 'losses' is the key for collection\n",
    "    # scope is for e.g. 'tower_0'\n",
    "    losses = tf.get_collection('losses', scope)\n",
    "\n",
    "    # Calculate the total loss for the current tower.\n",
    "    total_loss = tf.add_n(losses, name='total_loss')\n",
    "\n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Gradients\n",
    "  \"\"\"Calculate the average gradient for each shared variable across all towers.\n",
    "\n",
    "  Note that this function provides a synchronization point across all towers.\n",
    "\n",
    "  Args:\n",
    "    tower_grads: List of lists of (gradient, variable) tuples. The outer list\n",
    "      is over individual gradients. The inner list is over the gradient\n",
    "      calculation for each tower.\n",
    "  Returns:\n",
    "     List of pairs of (gradient, variable) where the gradient has been averaged\n",
    "     across all towers.\n",
    "  \"\"\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "    # Note that each grad_and_vars looks like the following:\n",
    "    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(axis=0, values=grads)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Training\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Create a variable to track the global step.\n",
    "global_step = tf.Variable(0, trainable=False)\n",
    "\n",
    "# create learning_decay\n",
    "# Decay the learning rate exponentially based on the number of steps.\n",
    "lr = tf.train.exponential_decay( learning_rate,\n",
    "                                 global_step,\n",
    "                                 decay_steps,\n",
    "                                 decay_rate, staircase=True )\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Use the optimizer to apply the gradients that minimize the loss\n",
    "# (and also increment the global step counter) as a single training step.\n",
    "optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "\n",
    "# Calculate the gradients for the batch of data on this SETI tower.\n",
    "#grads = opt.compute_gradients(loss)\n",
    "\n",
    "#train_op = optimizer.minimize(loss, global_step=global_step)\n",
    "#train_op = tf.train.AdamOptimizer(learning_rate=learning_rate).minimize(cross_entropy)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Get images and labels for SETI.\n",
    "x_batch, y_batch = dataset.train.next_batch(batch_size,shuffle=True)\n",
    "x_image = tf.reshape(x_batch, [-1,height,width,1]) \n",
    "labels = tf.reshape(y_batch,[-1,NUM_CLASSES])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# with tf.Session() as sess:\n",
    "#     with tf.name_scope(\"test12\"):\n",
    "#         logit1 = inference(x_image)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate the gradients for each model tower.\n",
    "tower_grads = []\n",
    "with tf.variable_scope(tf.get_variable_scope()):\n",
    "    for i in xrange(4):\n",
    "        with tf.device('/gpu:%d' % i):\n",
    "            with tf.name_scope('%s_%d' % ('tower_', i)) as scope:\n",
    "            # Dequeues one batch for the GPU\n",
    "            #image_batch, label_batch = batch_queue.dequeue()\n",
    "                x_batch, y_batch = dataset.train.next_batch(batch_size,shuffle=True)\n",
    "                image_batch = tf.reshape(x_batch, [-1,height,width,1]) \n",
    "                #label_batch = tf.reshape(y_batch,[-1,NUM_CLASSES])\n",
    "                # Calculate the loss for one tower of the SETI model. This function\n",
    "                # constructs the entire SETI model but shares the variables across\n",
    "                # all towers.\n",
    "                loss = tower_loss(scope, image_batch, y_batch)\n",
    "                # Reuse variables for the next tower.\n",
    "                tf.get_variable_scope().reuse_variables()\n",
    "                grads = optimizer.compute_gradients(loss)\n",
    "                tower_grads.append(grads)\n",
    "# on CPU                \n",
    "grads = average_gradients(tower_grads)\n",
    "# Apply the gradients to adjust the shared variables.\n",
    "apply_gradient_op = optimizer.apply_gradients(grads, global_step=global_step)\n",
    "\n",
    "# Track the moving averages of all trainable variables.\n",
    "variable_averages = tf.train.ExponentialMovingAverage(MOVING_AVERAGE_DECAY, global_step)\n",
    "variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "# Group all updates to into a single train op.\n",
    "# we call train_op in learning process\n",
    "# tf.group Creates an op that groups multiple operations.\n",
    "# When this op finishes, all ops in input have finished. This op has no output.\n",
    "train_op = tf.group(apply_gradient_op, variables_averages_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Evaluation"
   ]
  },
  {
   "cell_type": "raw",
   "metadata": {},
   "source": [
    "def evaluate():\n",
    "    X_test = dataset.test.images\n",
    "    image_test = tf.reshape(X_test, [-1,height,width,1]) \n",
    "    y_test = dataset.test.labels\n",
    "    # Build a Graph that computes the logits predictions from the\n",
    "    # inference model.\n",
    "    with tf.name_scope('xx') as scope:\n",
    "        logits_test = inference(image_test)\n",
    "        # Calculate predictions.\n",
    "    top_k_op = tf.nn.in_top_k(logits_test, y_test, 1)\n",
    "    return top_k_op\n",
    "with tf.name_scope(\"t\"):\n",
    "    evaluate()\n",
    "    \n",
    "correct_prediction = tf.equal(tf.argmax(logits,1), tf.argmax(y_,1))\n",
    "accuracy = tf.reduce_mean(tf.cast(correct_prediction, tf.float32))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Create checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "None\n"
     ]
    }
   ],
   "source": [
    "directory = os.path.dirname(chk_directory)\n",
    "try:\n",
    "    os.stat(directory)\n",
    "    ckpt = tf.train.get_checkpoint_state(chk_directory)\n",
    "    print ckpt\n",
    "except:\n",
    "    os.mkdir(directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "loss_values = []\n",
    "\n",
    "X_test = dataset.test.images\n",
    "y_test = dataset.test.labels\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "sess.run(init)\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "# load previously trained model if appilcable\n",
    "ckpt = tf.train.get_checkpoint_state(chk_directory)\n",
    "if ckpt:\n",
    "    print \"loading model: \",ckpt.model_checkpoint_path\n",
    "    #saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "\n",
    "    \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "694"
      ]
     },
     "execution_count": 22,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#step = 0\n",
    "num_examples = dataset.train.num_examples\n",
    "num_examples"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch: 0001 , g_step: 0313 , E_time= 8.03397 , lr= 0.005000000 , cost= 22.036649704\n",
      "Epoch: 0011 , g_step: 0443 , E_time= 8.00377 , lr= 0.005000000 , cost= 21.910421371\n",
      "Epoch: 0021 , g_step: 0573 , E_time= 7.96666 , lr= 0.005000000 , cost= 21.794521332\n",
      "Epoch: 0031 , g_step: 0703 , E_time= 7.95592 , lr= 0.005000000 , cost= 21.680685043\n",
      "Epoch: 0041 , g_step: 0833 , E_time= 8.00481 , lr= 0.005000000 , cost= 21.567886353\n",
      "Epoch: 0051 , g_step: 0963 , E_time= 7.98108 , lr= 0.005000000 , cost= 21.456047058\n",
      "Epoch: 0061 , g_step: 1093 , E_time= 8.03279 , lr= 0.004800000 , cost= 21.348415375\n",
      "Epoch: 0071 , g_step: 1223 , E_time= 7.97624 , lr= 0.004800000 , cost= 21.243017197\n",
      "Epoch: 0081 , g_step: 1353 , E_time= 8.03274 , lr= 0.004800000 , cost= 21.138525009\n",
      "Epoch: 0091 , g_step: 1483 , E_time= 8.04503 , lr= 0.004800000 , cost= 21.034910202\n",
      "Epoch: 0101 , g_step: 1613 , E_time= 7.99327 , lr= 0.004800000 , cost= 20.932205200\n",
      "Epoch: 0111 , g_step: 1743 , E_time= 7.96600 , lr= 0.004800000 , cost= 20.830383301\n",
      "Epoch: 0121 , g_step: 1873 , E_time= 7.94622 , lr= 0.004800000 , cost= 20.729234695\n",
      "Epoch: 0131 , g_step: 2003 , E_time= 7.96942 , lr= 0.004608000 , cost= 20.629058838\n",
      "Epoch: 0141 , g_step: 2133 , E_time= 8.06427 , lr= 0.004608000 , cost= 20.533426285\n",
      "Epoch: 0151 , g_step: 2263 , E_time= 8.01079 , lr= 0.004608000 , cost= 20.438364029\n",
      "Epoch: 0161 , g_step: 2393 , E_time= 8.02498 , lr= 0.004608000 , cost= 20.344038010\n",
      "Epoch: 0171 , g_step: 2523 , E_time= 7.96754 , lr= 0.004608000 , cost= 20.250373840\n",
      "Epoch: 0181 , g_step: 2653 , E_time= 8.00245 , lr= 0.004608000 , cost= 20.156850815\n",
      "Epoch: 0191 , g_step: 2783 , E_time= 8.02964 , lr= 0.004608000 , cost= 20.063903809\n",
      "Epoch: 0201 , g_step: 2913 , E_time= 7.96124 , lr= 0.004608000 , cost= 19.971605301\n",
      "Epoch: 0211 , g_step: 3043 , E_time= 7.96308 , lr= 0.004423679 , cost= 19.880849838\n",
      "Epoch: 0221 , g_step: 3173 , E_time= 8.01753 , lr= 0.004423679 , cost= 19.793062210\n",
      "Epoch: 0231 , g_step: 3303 , E_time= 8.00066 , lr= 0.004423679 , cost= 19.705764771\n",
      "Epoch: 0241 , g_step: 3433 , E_time= 7.95398 , lr= 0.004423679 , cost= 19.619216919\n",
      "Epoch: 0251 , g_step: 3563 , E_time= 7.96669 , lr= 0.004423679 , cost= 19.532260895\n",
      "Epoch: 0261 , g_step: 3693 , E_time= 7.96145 , lr= 0.004423679 , cost= 19.446081161\n",
      "Epoch: 0271 , g_step: 3823 , E_time= 8.00191 , lr= 0.004423679 , cost= 19.360334396\n",
      "Epoch: 0281 , g_step: 3953 , E_time= 8.01826 , lr= 0.004423679 , cost= 19.275030136\n",
      "Epoch: 0291 , g_step: 4083 , E_time= 8.02308 , lr= 0.004246732 , cost= 19.192073822\n",
      "('Wall Time:', '2399.1')\n",
      "Optimization Finished!\n",
      "model saved to /tmp/SETI1_train/save/model.ckpt\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "'/tmp/SETI1_train/save/model.ckpt-3600'"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Training cycle\n",
    "t_start = time.time()\n",
    "for epoch in range(training_epochs):\n",
    "    avg_loss = 0.\n",
    "    avg_accuracy = 0.\n",
    "    #dataset.shuffle_data()\n",
    "    total_batch = int(num_examples / batch_size)\n",
    "\n",
    "    # Loop over all batches in one epoch\n",
    "    start = time.time()\n",
    "    for step in range(total_batch):\n",
    "        _, loss_value = sess.run([train_op, loss])\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "    end = time.time()    \n",
    "    # Display model every 1 epochs\n",
    "    if epoch >= 0 and epoch % 10 == 0:\n",
    "        plr = sess.run(lr)\n",
    "        g_step = sess.run(global_step)\n",
    "        loss_values.append(loss_value)\n",
    "        print \"Epoch:\", '%04d' % (epoch+1) , \", g_step:\", '%04d' % (g_step) , \", E_time=\" , \"{:.5f}\".format(end - start) , \", lr=\", \"{:.9f}\".format(plr), \", cost=\", \"{:.9f}\".format(loss_value)\n",
    "t_end = time.time()\n",
    "print(\"Wall Time:\",\"{:.1f}\".format(t_end - t_start), \"sec\")\n",
    "print(\"Optimization Finished!\")\n",
    "print (\"model saved to {}\".format(checkpoint_path))\n",
    "saver.save(sess, checkpoint_path, global_step = (epoch+1)*step)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAX4AAAD8CAYAAABw1c+bAAAABHNCSVQICAgIfAhkiAAAAAlwSFlz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\nTkSuQmCC\n",
      "text/plain": [
       "<matplotlib.figure.Figure at 0x3fff8ded0f50>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([np.mean(loss_values[i:i+5]) for i in range(len(loss_values))])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Authors\n",
    "\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "#### Saeed Aghabozorgi\n",
    "\n",
    "[Saeed Aghabozorgi](https://ca.linkedin.com/in/saeedaghabozorgi), PhD is Sr. Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clientsâ€™ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
