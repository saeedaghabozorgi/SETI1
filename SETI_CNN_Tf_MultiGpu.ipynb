{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "<a href=\"https://www.cognitiveclass.ai\"><img src = \"https://cognitiveclass.ai/wp-content/themes/bdu3.0/static/images/cc-logo.png\" align = left></a>\n",
    "\n",
    "<br>\n",
    "<br>\n",
    "\n",
    "--------------------\n",
    "# Search for Extra Terrestrial Intelligence (SETI)\n",
    "###  SETI Signal Classification on PowerAI with Multi GPU\n",
    "<hr>\n",
    "<br>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Introduction\n",
    "In this Notebook, we will use the famous [SETI Dataset](https://github.com/setiQuest/ML4SETI/) to build a Convolutional Neural Networks capable to perform signals classification. CNN will say, with some associated error, what type of signal is the presented input. In this notebook, you will use IBM PowerAI with multiple GPU to train the model.\n",
    "\n",
    "### Project overview:\n",
    "Each night, using the Allen Telescope Array (ATA) in northern California, the SETI Institute scans the sky at various radio frequencies, observing star systems with known exoplanets, searching for faint but persistent signals. The current signal detection system is programmed to search only for particular kinds of signals: narrow-band carrier waves. However, the detection system sometimes triggers on signals that are not narrow-band signals  (with unknown efficiency) and are also not explicitly-known radio frequency interference (RFI). There seems to be various categories of these kinds of events that have been observed in the past.\n",
    "\n",
    "The goal of SETI is to classify these signals accurately in real-time. This may allow the signal detection system to make better observational decisions, increase the efficiency of the nightly scans, and allow for explicit detection of these other signal types.\n",
    "\n",
    "For more information refer to [SETI hackathon page](https://github.com/setiQuest/ML4SETI/).\n",
    "\n",
    "### Formulating the problem as image classification:\n",
    "Framing the radio signal data into spectrogram (a 2D visual representation), we can convert the problem into something akin to an image classification problem. Therefore we can run Convolutional Neural Network (CNN), will be run on the images which are the result of converting the signals to spectrogram.\n",
    "\n",
    "### Training on Multi-GPU:\n",
    "Running the CNN on large amound of data might take long time to train the model. Howerve, today, many systems contains Multiple GPUs for high performance computation. We can leverage this environments to run the training operation concurrently across multiple cards. One sample of these kind of environments is [IBM PowerAI](http://cocl.us/SETI-NIMBIX-PowerAI). In this notebook, we show you how to design and run your model on multiple GPUs."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "import requests\n",
    "import json\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "%matplotlib inline\n",
    "import tensorflow as tf\n",
    "import pickle\n",
    "import time\n",
    "#!sudo pip install sklearn\n",
    "import os\n",
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn import metrics\n",
    "from six.moves import urllib\n",
    "import sys\n",
    "import tarfile\n",
    "import re\n",
    "import math"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Set the destination folder"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "tmp/SETI1_data/\n",
      "tmp/SETI1_train/\n"
     ]
    }
   ],
   "source": [
    "### SET YOUR WORKING SPACE HERE! Use this folder to save intermediate results.\n",
    "dataset_name = 'SETI_ds_64x128'\n",
    "data_dir = \"tmp/SETI1_data/\"\n",
    "train_dir = 'tmp/SETI1_train/'\n",
    "\n",
    "# check point directory\n",
    "chk_directory = train_dir + '/save/'\n",
    "checkpoint_path = chk_directory + 'model.ckpt'\n",
    "\n",
    "# Create the  training and testing directories if not exist\n",
    "if os.path.exists(data_dir) is False:\n",
    "    os.makedirs(data_dir)\n",
    "print data_dir\n",
    "\n",
    "\n",
    "if os.path.exists(train_dir) is False:\n",
    "    os.makedirs(train_dir)\n",
    "print train_dir"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Import dataset reader\n",
    "The signals for this notebook, have been converted to spectogram images, and stored as 4 files.\n",
    "The following cell will load a python code that help us to decode the binary file, and read the SETI dataset."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Archive:  SETI.zip\n",
      "  inflating: SETI.py                 \n",
      "  inflating: __MACOSX/._SETI.py      \n"
     ]
    }
   ],
   "source": [
    "!wget -q --output-document  SETI.zip  https://ibm.box.com/shared/static/jhqdhcblhua5dx2t7ixwm88okitjrl6l.zip\n",
    "!unzip -o SETI.zip\n",
    "import SETI"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Download data\n",
    "The dataset exist and shared on IBM box. Running the following cell, you can download the dataset and extract it."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "('Successfully downloaded', 'qz33lcio9ip2j8qi2atxqs62gn3bnu2s.gz', 22528713, 'bytes.')\n",
      "Extracting to tmp/SETI1_data/SETI_ds_64x128\n"
     ]
    }
   ],
   "source": [
    "def maybe_download_and_extract():\n",
    "    DATA_URL =  'https://ibm.box.com/shared/static/qz33lcio9ip2j8qi2atxqs62gn3bnu2s.gz'\n",
    "    dest_directory = data_dir\n",
    "    if not os.path.exists(dest_directory):\n",
    "        os.makedirs(dest_directory)\n",
    "    filename = DATA_URL.split('/')[-1]\n",
    "    filepath = os.path.join(dest_directory, filename)\n",
    "    if not os.path.exists(filepath):\n",
    "        #print 'No zip file exist in ', filepath\n",
    "        def _progress(count, block_size, total_size):\n",
    "            sys.stdout.write('\\r>> Downloading %s %.1f%%' % (filename, float(count * block_size) / float(total_size) * 100.0))\n",
    "        sys.stdout.flush()\n",
    "        filepath, _ = urllib.request.urlretrieve(DATA_URL, filepath, _progress)\n",
    "\n",
    "    statinfo = os.stat(filepath)\n",
    "    print('Successfully downloaded', filename, statinfo.st_size, 'bytes.')\n",
    "    extracted_dir_path = os.path.join(dest_directory, dataset_name)\n",
    "    if not os.path.exists(extracted_dir_path):\n",
    "        print 'Extracting to', extracted_dir_path\n",
    "        tarfile.open(filepath, 'r:gz').extractall(dest_directory)\n",
    "maybe_download_and_extract()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Load data SETI"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting tmp/SETI1_data/SETI_ds_64x128/train-images-idx3-ubyte.gz\n",
      "Extracting tmp/SETI1_data/SETI_ds_64x128/train-labels-idx1-ubyte.gz\n",
      "Extracting tmp/SETI1_data/SETI_ds_64x128/test-images-idx3-ubyte.gz\n",
      "Extracting tmp/SETI1_data/SETI_ds_64x128/test-labels-idx1-ubyte.gz\n",
      "Number of time series: 3200\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "(3200, 8192)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ds_directory = data_dir + dataset_name\n",
    "dataset = SETI.read_data_sets(ds_directory, one_hot=True, validation_size=0)\n",
    "num_examples = dataset.train.num_examples\n",
    "print 'Number of time series:', num_examples\n",
    "dataset.train.images.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Understanding the imported data\n",
    "\n",
    "The imported data can be divided as follow:\n",
    "\n",
    "- Training (dataset.train) >>  Use the given dataset with inputs and related outputs for training of NN. In our case, if you give an image that you know that represents a \"class1\", this set will tell the neural network that we expect a \"class1\" as the output.  \n",
    "        - 3,200 signals (images)\n",
    "        - dataset.train.images for inputs\n",
    "        - dataset.train.labels for outputs\n",
    "  \n",
    "  \n",
    "- Test (dataset.test) >> the model does not have access to this informations prior to the test phase. It is used to evaluate the performance and accuracy of the model against \"real life situations\". No further optimization beyond this point.  \n",
    "        - 8,00 signals\n",
    "        - dataset.test.images for inputs\n",
    "        - dataset.test.labels for outputs\n",
    "        \n",
    "        \n",
    "#### Labels\n",
    "- Each image (spectrum of signal) in the dataset has been labeled from 1 to 4, representing:\n",
    "    - squiggle\n",
    "    - narrowband\n",
    "    - noise\n",
    "    - narrowbanddrd"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Network Parameters\n",
    "\n",
    "We place the parameters on CPU.   \n",
    "__Notice:__ This code is not optimal for single-GPU training due to the cost of copying parameters between CPU and GPU."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Parameters\n",
    "decay_rate=0.92  #decay every 1500 steps with a base of 0.92:\n",
    "decay_steps=1500\n",
    "learning_rate = 0.005\n",
    "training_epochs = 5000\n",
    "batch_size = 128\n",
    "display_step = 100\n",
    "moving_avg_decay = 0.9999     # The decay to use for the moving average.\n",
    "\n",
    "#check point directory\n",
    "chk_directory = train_dir +'/save/'\n",
    "checkpoint_path = chk_directory + 'model.ckpt'\n",
    "\n",
    "\n",
    "num_classes = 4 # number of possible classes for the problem\n",
    "\n",
    "\n",
    "height = 64 # height of the image in pixels \n",
    "width = 128 # width of the image in pixels \n",
    "n_input = width * height # number of pixels in one image \n",
    "num_GPUs = 4\n",
    "\n",
    "#log file directory\n",
    "log_dir = train_dir + 'log-'+str(num_GPUs)+'-'+str(learning_rate)+'-'+str(decay_rate)+'-'+str(decay_steps)+'-0'"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In following cell, we fill a queue with a portion of SETI images, to be used in each GPUs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "def read_inputs():\n",
    "    train_img_ds = dataset.train.images\n",
    "    image = tf.convert_to_tensor(train_img_ds, np.float32)\n",
    "    image = tf.reshape(image, [-1,height,width,1], name = 'images')\n",
    "    train_lb_ds = dataset.train.labels\n",
    "    label = tf.convert_to_tensor(train_lb_ds, np.float32)\n",
    "    label = tf.reshape(label, [-1,4], name = 'labels')\n",
    "    \n",
    "    min_fraction_of_examples_in_queue = 0.2\n",
    "    min_queue_examples = int(num_examples *  min_fraction_of_examples_in_queue)\n",
    "    print ('Filling queue with %d SETI images before starting to train. '\n",
    "    'This will take a few minutes.' % min_queue_examples)\n",
    "    num_preprocess_threads = 16\n",
    "    images, labels = tf.train.shuffle_batch([image, label], batch_size=batch_size,\n",
    "        num_threads=num_preprocess_threads,\n",
    "        capacity=min_queue_examples + 3 * batch_size,\n",
    "        min_after_dequeue=min_queue_examples, enqueue_many=True)\n",
    "    return(images,labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### How to use multi GPU for training?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "PowerAI supports multi-GPU calculation.  Given multiple GPU cards, we run the SETI model on each GPU as following:\n",
    "\n",
    "    1. Store all model parameters on the CPU, e.g weights and biases.\n",
    "    2. Put a copy of the SETI model on each GPU, including conv2d, pre-activation, relu, etc.\n",
    "    3. Divide up a large batch of data across the GPUs, and feed each model replica with a unique batch of data.\n",
    "    4. Compute the inference on each GPU\n",
    "    5. Calculate the gradients on each GPU\n",
    "    6. Wait until all GPUs finish processing of their batches\n",
    "    7. Update model parameters synchronously on CPU"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Variable definitions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "We define all variables using __tf.get_variable()__ in order to place the variables on CPU to be shares across multiple GPU for training. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def _variable_on_cpu(name, shape, initializer):\n",
    "    with tf.device('/cpu:0'):\n",
    "        var = tf.get_variable(name, shape, initializer=initializer, dtype=tf.float32)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def _variable_with_weight_decay(name, shape, stddev, wd):\n",
    "    var = _variable_on_cpu( name, shape ,tf.truncated_normal_initializer(stddev=stddev, dtype=tf.float32))\n",
    "    if wd is not None:\n",
    "        weight_decay = tf.multiply(tf.nn.l2_loss(var), wd, name='weight_loss')\n",
    "        tf.add_to_collection('losses', weight_decay)\n",
    "    return var"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Inference\n",
    "\n",
    "This function builds the graph as far as required for running the network forward to make predictions."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def inference(images):\n",
    "\n",
    "    # conv1\n",
    "    with tf.variable_scope('conv1') as scope: # a sample variable would be conv1/weights\n",
    "        kernel = _variable_with_weight_decay('weights', shape=[5, 5, 1, 32], stddev=0.1,  wd=0.0)\n",
    "        conv = tf.nn.conv2d(images, kernel, strides=[1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [32], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv1 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "    # pool1\n",
    "    pool1 = tf.nn.max_pool(conv1, ksize=[1, 2, 2, 1], strides=[1, 2, 2, 1], padding='SAME', name='pool1')\n",
    "    # norm1\n",
    "    norm1 = tf.nn.lrn(pool1, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75, name='norm1')\n",
    "\n",
    "    # conv2\n",
    "    with tf.variable_scope('conv2') as scope:\n",
    "        kernel = _variable_with_weight_decay('weights', shape=[5, 5, 32, 64],  stddev=0.1,  wd=0.0)\n",
    "        conv = tf.nn.conv2d(norm1, kernel, [1, 1, 1, 1], padding='SAME')\n",
    "        biases = _variable_on_cpu('biases', [64], tf.constant_initializer(0.1))\n",
    "        pre_activation = tf.nn.bias_add(conv, biases)\n",
    "        conv2 = tf.nn.relu(pre_activation, name=scope.name)\n",
    "\n",
    "    # norm2\n",
    "    norm2 = tf.nn.lrn(conv2, 4, bias=1.0, alpha=0.001 / 9.0, beta=0.75,  name='norm2')\n",
    "    # pool2\n",
    "    pool2 = tf.nn.max_pool(norm2, ksize=[1, 2, 2, 1], strides=[1, 4, 4, 1], padding='SAME', name='pool2')\n",
    "    \n",
    "    \n",
    "    # local3\n",
    "    with tf.variable_scope('local3') as scope:\n",
    "        # Move everything into depth so we can perform a single matrix multiply.\n",
    "        reshape = tf.reshape(pool2, [batch_size, -1])\n",
    "        dim = reshape.get_shape()[1].value\n",
    "        weights = _variable_with_weight_decay('weights', shape=[dim, 1024], stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [1024], tf.constant_initializer(0.1))\n",
    "        local3 = tf.nn.relu(tf.matmul(reshape, weights) + biases, name=scope.name)\n",
    "\n",
    "    # local4\n",
    "    with tf.variable_scope('local4') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', shape=[1024, 256],  stddev=0.04, wd=0.004)\n",
    "        biases = _variable_on_cpu('biases', [256], tf.constant_initializer(0.1))\n",
    "        local4 = tf.nn.relu(tf.matmul(local3, weights) + biases, name=scope.name)\n",
    "        #_activation_summary(local4)\n",
    "\n",
    "    # linear layer(WX + b),\n",
    "    # We don't apply softmax here because tf.nn.sparse_softmax_cross_entropy_with_logits accepts the unscaled logits and performs the softmax internally for efficiency.\n",
    "    with tf.variable_scope('softmax_linear') as scope:\n",
    "        weights = _variable_with_weight_decay('weights', [256, num_classes],  stddev=1/256.0, wd=0.0)\n",
    "        biases = _variable_on_cpu('biases', [num_classes], tf.constant_initializer(0.0))\n",
    "        softmax_linear = tf.add(tf.matmul(local4, weights), biases, name=scope.name)\n",
    "\n",
    "    return softmax_linear"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Loss function\n",
    "\n",
    "As we want to run the CNN on multiple GPUs, we construct our model in a multi-tower fashion where each tower is assigned to a different GPU. The following function calculate the loss value for each tower.  \n",
    "\n",
    "\n",
    "loss function, adds the ops required to generate loss, to the inference graph. It calculates the average cross entropy loss across the batch.  \n",
    "\n",
    "__Notice:__ The total loss s defined as the cross entropy loss plus all of the weight decay terms (L2 loss)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Calculate the total loss on a single tower running the SETI model.\n",
    "def tower_loss(scope, logits, labels):\n",
    "    # Build inference Graph.\n",
    "    labels = tf.cast(labels, tf.int64)\n",
    "    cross_entropy = tf.nn.softmax_cross_entropy_with_logits(labels=labels, logits=logits, name='cross_entropy_per_example')\n",
    "    cross_entropy_mean = tf.reduce_mean(cross_entropy, name='cross_entropy')\n",
    "    tf.add_to_collection('losses', cross_entropy_mean)\n",
    "\n",
    "    # Assemble all of the losses for the current tower only.\n",
    "    # 'losses' is the key for collection\n",
    "    # scope is for e.g. 'tower_0'\n",
    "    losses = tf.get_collection('losses', scope)\n",
    "\n",
    "    # Calculate the total loss for the current tower.\n",
    "    total_loss = tf.add_n(losses, name='total_loss')\n",
    "    \n",
    "    # Attach a scalar summary to all individual losses and the total loss; do the\n",
    "    # same for the averaged version of the losses.\n",
    "    for l in losses + [total_loss]:\n",
    "        loss_name = re.sub('%s_[0-9]*/' % 'tower_GPU', '', l.op.name)\n",
    "        tf.summary.scalar(loss_name, l)\n",
    "    \n",
    "    return total_loss"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Averaging Gradients \n",
    "\n",
    "Calculating the gradients on each tower, results in 4 group of gradients, stored in __tower_grads__. The following  function takes __tower_grads__, and calculates the average gradient for each shared variable across all towers.\n",
    "Notice: that this function provides a synchronization point across all towers.\n",
    "\n",
    " - tower_grads: List of lists of (gradient, variable) tuples. The outer list is over individual gradients. The inner list is over the gradient calculation for each tower.\n",
    "\n",
    "This function returns list of pairs of (gradient, variable) where the gradient has been averaged across all towers.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def average_gradients(tower_grads):\n",
    "    average_grads = []\n",
    "    for grad_and_vars in zip(*tower_grads):\n",
    "    # Note that each grad_and_vars looks like the following:\n",
    "    #   ((grad0_gpu0, var0_gpu0), ... , (grad0_gpuN, var0_gpuN))\n",
    "        grads = []\n",
    "        for g, _ in grad_and_vars:\n",
    "            # Add 0 dimension to the gradients to represent the tower.\n",
    "            expanded_g = tf.expand_dims(g, 0)\n",
    "\n",
    "            # Append on a 'tower' dimension which we will average over below.\n",
    "            grads.append(expanded_g)\n",
    "\n",
    "        # Average over the 'tower' dimension.\n",
    "        grad = tf.concat(axis=0, values=grads)\n",
    "        grad = tf.reduce_mean(grad, 0)\n",
    "\n",
    "        # Keep in mind that the Variables are redundant because they are shared\n",
    "        # across towers. So .. we will just return the first tower's pointer to\n",
    "        # the Variable.\n",
    "        v = grad_and_vars[0][1]\n",
    "        grad_and_var = (grad, v)\n",
    "        average_grads.append(grad_and_var)\n",
    "    return average_grads"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Training\n",
    " - The following cell, creates a graph to run one step of training with respect to the loss.\n",
    " - It creates an optimizer and apply to all trainable variables. Add moving\n",
    "  average for all trainable variables.\n",
    " - When training a model, it is often recommended to lower the learning rate as the training progresses. \n",
    "This function applies an exponential decay function to a provided initial learning rate!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "with tf.device('/cpu:0'):\n",
    "    # These varibales are defined on CPU\n",
    "    # with tf.Graph().as_default(), tf.device('/cpu:0'):\n",
    "    # Create a variable to track the global step.\n",
    "    global_step = tf.Variable(0, name='global_step', trainable=False)\n",
    "\n",
    "    # create learning_decay\n",
    "    lr = tf.train.exponential_decay( learning_rate,\n",
    "                                     global_step,\n",
    "                                     decay_steps,\n",
    "                                     decay_rate, staircase=True )\n",
    "    \n",
    "    # Use the optimizer \n",
    "    optimizer = tf.train.GradientDescentOptimizer(lr)\n",
    "    \n",
    "    tf.summary.scalar('learning_rate', lr)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "\n",
    " - We choose a unique name for all operations within a tower. e.g. all operations in the first tower are prepended with tower_GPU0. We do it using name_scope(). It defines __operations__ with unique prefix name within each tower on the corresponding GPU. \n",
    " - All variables are placed to the CPU and accessed via tf.get_variable (no variable on GPUs).\n",
    " - we create a **train_op**, where we apply:\n",
    "     - Gradients on all weights and biases in CPU.\n",
    "     - Moving Average on all trainable variables.\n",
    " - **train_op** would be called later in the training process."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Get images and labels for the model.\n",
    "images, labels = read_inputs()\n",
    "batch_queue = tf.contrib.slim.prefetch_queue.prefetch_queue([images, labels], capacity=2 * num_GPUs)\n",
    "\n",
    "# Calculate the gradients for each model tower.\n",
    "with tf.device('/cpu:0'):\n",
    "    towers_grads = []\n",
    "    with tf.variable_scope(tf.get_variable_scope()): # It is defined to share/reuse all the variables on CPU.\n",
    "        for i in xrange(num_GPUs):\n",
    "            with tf.device('/gpu:%d' % i):\n",
    "                with tf.name_scope('%s_%d' % ('tower_GPU', i)) as nscope:\n",
    "                    # read one batch for the GPU\n",
    "                    image_batch, label_batch = batch_queue.dequeue()\n",
    "                    \n",
    "                    # Build inference part of the Graph.\n",
    "                    logits = inference(image_batch) # it builds a subgraph on twoer with all the operations, to use the shared variables.\n",
    "\n",
    "                    # This function constructs the entire SETI model, calling inference.\n",
    "                    # It shares the variables across all towers (e.g. conv1/weights).\n",
    "                    # Calculate the loss for one tower of the SETI model. \n",
    "                    loss = tower_loss(nscope, logits, label_batch)\n",
    " \n",
    "                    # For the next tower, when we call tower_loss() again, it calls inference(), and tries to create new variables.\n",
    "                    # For example, it tries to create conv1/weights, again.\n",
    "                    # We will reuse variables for the next tower. \n",
    "                    tf.get_variable_scope().reuse_variables()\n",
    "                    \n",
    "                    # Grads is a list over the gradient calculation for each tower.\n",
    "                    # its shape looks like [(<tensor>,<variable>), (<tensor>,<variable>), ..]\n",
    "                    # where, <tensor> is gradient value of <variable>\n",
    "                    tower_grads = optimizer.compute_gradients(loss)\n",
    "                    towers_grads.append(tower_grads)\n",
    "\n",
    "    # calculate avg gradients on CPU                \n",
    "    avg_grads = average_gradients(towers_grads)\n",
    "    \n",
    "    # Apply the gradients to adjust the shared variables\n",
    "    apply_gradient_op = optimizer.apply_gradients(avg_grads, global_step=global_step)\n",
    "\n",
    "    # Track the moving averages of all trainable variables\n",
    "    with tf.name_scope('Moving_Avg_Decay'):\n",
    "        variable_averages = tf.train.ExponentialMovingAverage(moving_avg_decay, global_step, name= 'variable_averages')\n",
    "        variables_averages_op = variable_averages.apply(tf.trainable_variables())\n",
    "\n",
    "    # Group all updates to into a single train op.\n",
    "    # we call train_op in learning process\n",
    "    # tf.group Creates an op that groups multiple operations.\n",
    "    # When this op finishes, all ops in input have finished. This op has no output.\n",
    "    train_op = tf.group(apply_gradient_op, variables_averages_op)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "You can check the constructed graph here:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "\n",
       "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"\n",
       "        <script>\n",
       "          function load() {\n",
       "            document.getElementById(&quot;graph0.548927348089&quot;).pbtxt = '';\n",
       "          }\n",
       "        </script>\n",
       "        <link rel=&quot;import&quot; href=&quot;https://tensorboard.appspot.com/tf-graph-basic.build.html&quot; onload=load()>\n",
       "        <div style=&quot;height:600px&quot;>\n",
       "          <tf-graph-basic id=&quot;graph0.548927348089&quot;></tf-graph-basic>\n",
       "        </div>\n",
       "    \"></iframe>\n",
       "    "
      ],
      "text/plain": [
       "<IPython.core.display.HTML object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Helper functions for TF Graph visualization\n",
    "# The following code is from Alex Mordvintsev deep dream notebook from\n",
    "# https://github.com/tensorflow/tensorflow/blob/master/tensorflow/examples/tutorials/deepdream/deepdream.ipynb\n",
    "\n",
    "\n",
    "from IPython.display import clear_output, Image, display, HTML\n",
    "\n",
    "def strip_consts(graph_def, max_const_size=32):\n",
    "    \"\"\"Strip large constant values from graph_def.\"\"\"\n",
    "    strip_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = strip_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        if n.op == 'Const':\n",
    "            tensor = n.attr['value'].tensor\n",
    "            size = len(tensor.tensor_content)\n",
    "            if size > max_const_size:\n",
    "                tensor.tensor_content = tf.compat.as_bytes(\"<stripped %d bytes>\"%size)\n",
    "    return strip_def\n",
    "  \n",
    "def rename_nodes(graph_def, rename_func):\n",
    "    res_def = tf.GraphDef()\n",
    "    for n0 in graph_def.node:\n",
    "        n = res_def.node.add() \n",
    "        n.MergeFrom(n0)\n",
    "        n.name = rename_func(n.name)\n",
    "        for i, s in enumerate(n.input):\n",
    "            n.input[i] = rename_func(s) if s[0]!='^' else '^'+rename_func(s[1:])\n",
    "    return res_def\n",
    "  \n",
    "def show_graph(graph_def, max_const_size=32):\n",
    "    \"\"\"Visualize TensorFlow graph.\"\"\"\n",
    "    if hasattr(graph_def, 'as_graph_def'):\n",
    "        graph_def = graph_def.as_graph_def()\n",
    "    strip_def = strip_consts(graph_def, max_const_size=max_const_size)\n",
    "    code = \"\"\"\n",
    "        <script>\n",
    "          function load() {{\n",
    "            document.getElementById(\"{id}\").pbtxt = {data};\n",
    "          }}\n",
    "        </script>\n",
    "        <link rel=\"import\" href=\"https://tensorboard.appspot.com/tf-graph-basic.build.html\" onload=load()>\n",
    "        <div style=\"height:600px\">\n",
    "          <tf-graph-basic id=\"{id}\"></tf-graph-basic>\n",
    "        </div>\n",
    "    \"\"\".format(data=repr(str(strip_def)), id='graph'+str(np.random.rand()))\n",
    "  \n",
    "    iframe = \"\"\"\n",
    "        <iframe seamless style=\"width:800px;height:620px;border:0\" srcdoc=\"{}\"></iframe>\n",
    "    \"\"\".format(code.replace('\"', '&quot;'))\n",
    "    display(HTML(iframe))\n",
    "\n",
    "\n",
    "graph_def = tf.get_default_graph().as_graph_def()\n",
    "tmp_def = rename_nodes(graph_def, lambda s:\"/\".join(s.split('_',1)))\n",
    "show_graph(tmp_def)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "#### Evaluation\n",
    "In the following cell we build all the operations for calculating the accuracy of the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "x_ph  = tf.placeholder(tf.float32, shape=[None, n_input], name = 'x_ph')\n",
    "y_ph = tf.placeholder(tf.float32, shape=[None, num_classes], name = 'y_ph')\n",
    "def build_evaluation_graph():\n",
    "    with tf.variable_scope(tf.get_variable_scope()) as scope:\n",
    "        tf.get_variable_scope().reuse_variables()\n",
    "        image_test = tf.reshape(x_ph, [-1,height,width,1], name = 'image_test') \n",
    "        logits_test = inference(image_test)\n",
    "        pred = tf.cast(logits_test, tf.float32)\n",
    "        top_k_op = tf.nn.in_top_k(pred,tf.argmax(y_ph,1) , 1)\n",
    "        return top_k_op\n",
    "top_k_op = build_evaluation_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "def evaluate():\n",
    "    with tf.variable_scope(tf.get_variable_scope()):\n",
    "        num_iter = int(math.ceil(dataset.test.num_examples / batch_size))\n",
    "        true_count = 0  # Counts the number of correct predictions.\n",
    "        total_sample_count = num_iter * batch_size\n",
    "        step = 0\n",
    "        while step < num_iter:\n",
    "            x_batch, y_batch = dataset.test.next_batch(batch_size)\n",
    "            correct_count = np.sum(sess.run(top_k_op, feed_dict={x_ph: x_batch, y_ph: y_batch}))\n",
    "            true_count += correct_count\n",
    "            #print true_count\n",
    "            step += 1\n",
    "\n",
    "        # Compute precision @ 1.\n",
    "        precision = true_count*1.0 / total_sample_count\n",
    "        #tf.summary.scalar('precision', precision)\n",
    "        return precision\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Create checkpoint directory"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "model_checkpoint_path: \"tmp/SETI1_train//save/model.ckpt-1200\"\n",
      "all_model_checkpoint_paths: \"tmp/SETI1_train//save/model.ckpt-800\"\n",
      "all_model_checkpoint_paths: \"tmp/SETI1_train//save/model.ckpt-900\"\n",
      "all_model_checkpoint_paths: \"tmp/SETI1_train//save/model.ckpt-1000\"\n",
      "all_model_checkpoint_paths: \"tmp/SETI1_train//save/model.ckpt-1100\"\n",
      "all_model_checkpoint_paths: \"tmp/SETI1_train//save/model.ckpt-1200\"\n",
      "\n"
     ]
    }
   ],
   "source": [
    "directory = os.path.dirname(chk_directory)\n",
    "try:\n",
    "    os.stat(directory)\n",
    "    ckpt = tf.train.get_checkpoint_state(chk_directory)\n",
    "    print ckpt\n",
    "except:\n",
    "    os.mkdir(directory) "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Training\n",
    "Lets initialize all the variable, and resotre the previous trained model if have any"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "# Initializing the variables\n",
    "init = tf.global_variables_initializer()\n",
    "loss_values = []\n",
    "\n",
    "X_test = dataset.test.images\n",
    "y_test = dataset.test.labels\n",
    "\n",
    "sess = tf.Session(config=tf.ConfigProto(allow_soft_placement=True))\n",
    "sess.run(init)\n",
    "merged_op = tf.summary.merge_all()\n",
    "train_writer = tf.summary.FileWriter(log_dir, sess.graph)\n",
    "saver = tf.train.Saver(tf.global_variables())\n",
    "\n",
    "# Start the queue runners.\n",
    "tf.train.start_queue_runners(sess=sess)\n",
    "\n",
    "\n",
    "# load previously trained model if appilcable\n",
    "ckpt = tf.train.get_checkpoint_state(chk_directory)\n",
    "if ckpt:\n",
    "    print \"loading model: \",ckpt.model_checkpoint_path\n",
    "    #saver.restore(sess, ckpt.model_checkpoint_path)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "In this step, we start training model by looping over all batches in each epoch, feeding the graph, and calculating the new weights."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "print 'Training dataset size:',num_examples, ' Signals'\n",
    "print 'Testing dataset size:',dataset.test.num_examples, ' Signals'\n",
    "print 'Total epochs:', training_epochs\n",
    "print 'Batch size:', batch_size\n",
    "total_batch = int(num_examples / batch_size)\n",
    "print 'Total batchs per epoch:',total_batch\n",
    "# Training cycle\n",
    "tr_start = time.time()\n",
    "for epoch in range(training_epochs):\n",
    "    ep_start = time.time()\n",
    "    avg_accuracy = 0.\n",
    "\n",
    "    # Loop over all batches in one epoch\n",
    "    for step in range(total_batch):\n",
    "        t_start = time.time()\n",
    "        _, loss_value = sess.run([train_op, loss])\n",
    "        duration = time.time() - t_start\n",
    "        assert not np.isnan(loss_value), 'Model diverged with loss = NaN'\n",
    "    \n",
    "    \n",
    "    # Save model every x epochs\n",
    "    if epoch >= 0 and epoch % 100 == 0:\n",
    "        saver.save(sess, checkpoint_path, global_step = epoch)\n",
    "    \n",
    "    # Summarize model every x epochs\n",
    "    if epoch >= 0 and epoch % 1 == 0:\n",
    "        #print 'merged'\n",
    "        summary = sess.run(merged_op)    \n",
    "        train_writer.add_summary(summary, epoch)\n",
    "    \n",
    "    \n",
    "    # Display model every 1 epochs\n",
    "    if epoch >= 0 and epoch % 50 == 0:\n",
    "        plr = sess.run(lr)\n",
    "        g_step = sess.run(global_step)\n",
    "        loss_values.append(loss_value)\n",
    "        sec_per_batch = duration / num_GPUs\n",
    "        test_eval = evaluate()\n",
    "        summ = tf.Summary()\n",
    "        summ.ParseFromString(sess.run(merged_op))\n",
    "        summ.value.add(tag='Precision @ 1', simple_value=test_eval)\n",
    "        train_writer.add_summary(summ, epoch)\n",
    "        print(\"Epoch:\"+ '%04d' % (epoch) + \\\n",
    "        \", Ep_time=\" + \"{:.2f}\".format(time.time() - ep_start) + \\\n",
    "        \", g_step:\" + '%04d' % (g_step) + \\\n",
    "        \", lr=\" + \"{:.9f}\".format(plr) + \\\n",
    "        \", cost=\" + \"{:.3f}\".format(loss_value) + \\\n",
    "        #\", Train_Acc=\" + \"{:.2f}\".format(avg_train_acc) + \\\n",
    "        \", Test_Acc=\" + \"{:.2f}\".format(test_eval) + \n",
    "        \", Batch (sec)=\" + \"{:.3f}\".format(sec_per_batch)  ) \n",
    "        \n",
    "print(\"Wall Time:\",\"{:.1f}\".format((time.time() - tr_start)/60.0, \"Min\"))\n",
    "print(\"Optimization Finished!\")\n",
    "print (\"model saved to {}\".format(checkpoint_path))\n",
    "saver.save(sess, checkpoint_path, global_step = (epoch+1)*step)\n",
    "train_writer.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Lets see how the coss value changes over time."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": [
    "%matplotlib inline\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "plt.plot([np.mean(loss_values[i:i+5]) for i in range(len(loss_values))])\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Evaluation\n",
    "Accuracy is depend on the number of epoch that you set in partametrs part."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "with tf.variable_scope(tf.get_variable_scope()):\n",
    "    tf.get_variable_scope().reuse_variables()\n",
    "    num_iter = int(math.ceil(dataset.test.num_examples / batch_size))\n",
    "    step = 0\n",
    "    pred_dict=[]\n",
    "    while step < num_iter:\n",
    "        #print step\n",
    "        x_batch, y_test = dataset.test.next_batch(batch_size)\n",
    "        image_test = tf.reshape(x_batch, [-1,height,width,1], name = 'image_test') \n",
    "        logits_test = inference(image_test)\n",
    "        pred = tf.cast(logits_test, tf.float32)\n",
    "        pred_lbl = sess.run(pred)\n",
    "        pred_dict.append((y_test, pred_lbl))\n",
    "        step += 1\n",
    "y_pred = [] # predicted\n",
    "y_lb = [] # ground truth labels\n",
    "y_pred_lb = [] # predicted labels\n",
    "for item in pred_dict:\n",
    "    for hotcode_val in item[0]:\n",
    "        y_lb.append(np.argmax(hotcode_val)) # ground truth\n",
    "    for hotcode_val in item[1]:\n",
    "        y_pred.append(hotcode_val)\n",
    "        y_pred_lb.append(np.argmax(hotcode_val)) # ground truth\n",
    "print \"Confusion Matrix:\"\n",
    "print metrics.confusion_matrix(y_true= y_lb, y_pred= y_pred_lb)\n",
    "print \"Precision:\"\n",
    "print metrics.classification_report(y_true= y_lb, y_pred= y_pred_lb)\n",
    "print(\"Classification accuracy: %0.6f\" % metrics.accuracy_score(y_true= y_lb, y_pred= y_pred_lb) )\n",
    "print(\"Log Loss: %0.6f\" % metrics.log_loss(y_true= y_lb, y_pred= y_pred))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "__Notice:__ The model is not optimized to reach to highest accuracy, and you can achive better results tuning the parameters."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Benchmark:\n",
    "- SETI_multi_gpu_train.py achieves ~70% accuracy after 3k epochs of data (45K steps).\n",
    "- Speed: With batch_size 128.  \n",
    "\n",
    "\n",
    "\n",
    "|          System              |   Step Time (sec/batch)   |         Accuracy                 |\n",
    "| ---------------------------- | :-----------------------: |--------------------------------: |\n",
    "| 4 P100 GPUs w/NVLink np8g4   |       ~0.017              | ~72% at 74K steps  (1.5 hours)   |\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "## Want to learn more?\n",
    "\n",
    "[Deep Learning with TensorFlow](http://cocl.us/SETI-NIMBIX-ML0102EN) is a free course in __cognitiveclass.ia__ where you can learn TensorFlow and Deep Learning togetherwe.\n",
    "\n",
    "Also, running deep learning programs usually needs a high performance platform. PowerAI speeds up deep learning and AI. Built on IBM's Power Systems, PowerAI is a scalable software platform that accelerates deep learning and AI with blazing performance for individual users or enterprises. The PowerAI platform supports popular machine learning libraries and dependencies including Tensorflow, Caffe, Torch, and Theano. You can download a [free version of PowerAI](http://cocl.us/SETI-NIMBIX-PowerAI)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "source": [
    "### Authors\n",
    "\n",
    "<div class=\"teacher-image\" style=\"    float: left;\n",
    "    width: 115px;\n",
    "    height: 115px;\n",
    "    margin-right: 10px;\n",
    "    margin-bottom: 10px;\n",
    "    border: 1px solid #CCC;\n",
    "    padding: 3px;\n",
    "    border-radius: 3px;\n",
    "    text-align: center;\"><img class=\"alignnone wp-image-2258 \" src=\"https://ibm.box.com/shared/static/tyd41rlrnmfrrk78jx521eb73fljwvv0.jpg\" alt=\"Saeed Aghabozorgi\" width=\"178\" height=\"178\" /></div>\n",
    "#### Saeed Aghabozorgi\n",
    "\n",
    "[Saeed Aghabozorgi](https://ca.linkedin.com/in/saeedaghabozorgi), PhD is Sr. Data Scientist in IBM with a track record of developing enterprise level applications that substantially increases clientsâ€™ ability to turn data into actionable knowledge. He is a researcher in data mining field and expert in developing advanced analytic methods like machine learning and statistical modelling on large datasets.</p>\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "button": false,
    "collapsed": true,
    "new_sheet": false,
    "run_control": {
     "read_only": false
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
